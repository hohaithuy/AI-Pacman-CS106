{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS106-Q_Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hohaithuy/AI-Pacman-CS106/blob/main/CS106_Q_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8P_laMcSQNk"
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xifGZ8j-SWPT"
      },
      "source": [
        "env = gym.make('FrozenLake-v0')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q-Learning"
      ],
      "metadata": {
        "id": "h58msIJk3JQ_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpG5Q7_XSdPw",
        "outputId": "381a4deb-6902-470e-9bb9-10c974392c1a"
      },
      "source": [
        "# Initialize Q-value table randomly\n",
        "q_table = np.zeros((env.observation_space.n, env.action_space.n))\n",
        "print(q_table)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFsyfXH5Ssd6"
      },
      "source": [
        "# Hyperparameters\n",
        "gamma = 0.99\n",
        "learning_rate = 0.1\n",
        "max_epsilon = 1.0\n",
        "min_epsilon = 0.01\n",
        "epsilon_decay_rate = 0.005\n",
        "\n",
        "num_episodes = 20000\n",
        "num_steps_per_episode = 100"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3xVez-WTeww"
      },
      "source": [
        "def q_learning(env, num_episodes, num_steps_per_episode, learning_rate, gamma, max_epsilon, min_epsilon, epsilon_decay_rate):\n",
        "    q_table = np.zeros((env.observation_space.n, env.action_space.n))\n",
        "    rewards_all = []\n",
        "    for episode in range(num_episodes):\n",
        "        state = env.reset()\n",
        "\n",
        "        reward_episode = 0.0\n",
        "        done = False\n",
        "        epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-epsilon_decay_rate*episode)\n",
        "        for step in range(num_steps_per_episode):\n",
        "            exploration = random.uniform(0,1)\n",
        "            if exploration < epsilon:\n",
        "                action = env.action_space.sample()\n",
        "            else:\n",
        "                action = np.argmax(q_table[state, :])\n",
        "\n",
        "            next_state, reward, done, info = env.step(action)\n",
        "            q_table[state, action] = q_table[state, action] * (1 - learning_rate) + learning_rate * (reward + gamma * np.max(q_table[next_state,:]))\n",
        "\n",
        "            reward_episode += reward\n",
        "            state = next_state\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "        rewards_all.append(reward_episode)\n",
        "    print(f'Episode {episode} finished')\n",
        "    return q_table, rewards_all"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TEST"
      ],
      "metadata": {
        "id": "gJRQvOUd3Ebg"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmauQUIQVOWr",
        "outputId": "5ab61d9a-7163-4902-8a12-cc6ad05be4ba"
      },
      "source": [
        "q_table, rewards_all = q_learning(env, num_episodes, num_steps_per_episode, learning_rate, gamma, max_epsilon, min_epsilon, epsilon_decay_rate)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 19999 finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBf-s9wsVX5Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0491af9d-19f8-445f-c4de-ca1cc3b09366"
      },
      "source": [
        "q_table"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.59815267, 0.52704808, 0.51828891, 0.50471752],\n",
              "       [0.23055112, 0.28765303, 0.23299557, 0.43090304],\n",
              "       [0.3975804 , 0.22651537, 0.23006189, 0.30742742],\n",
              "       [0.1887658 , 0.        , 0.        , 0.        ],\n",
              "       [0.62072763, 0.35982193, 0.32465072, 0.43216566],\n",
              "       [0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.15283387, 0.12008668, 0.327298  , 0.10527145],\n",
              "       [0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.43030108, 0.39065775, 0.43333165, 0.65899706],\n",
              "       [0.35539006, 0.70523842, 0.47541626, 0.36466339],\n",
              "       [0.76550288, 0.35993733, 0.33011948, 0.31737901],\n",
              "       [0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.46299143, 0.59684331, 0.82336505, 0.44776503],\n",
              "       [0.75899014, 0.94633304, 0.80260274, 0.70904058],\n",
              "       [0.        , 0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MAozcopVdi_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac8c9102-1e21-48a9-d01d-8e6699271266"
      },
      "source": [
        "print(sum(rewards_all))\n",
        "print(sum(rewards_all[0:1000]))\n",
        "print(sum(rewards_all[1000:2000]))\n",
        "print(sum(rewards_all[2000:3000]))\n",
        "print(sum(rewards_all[9000:10000]))\n",
        "print(sum(rewards_all[11000:12000]))\n",
        "print(sum(rewards_all[14000:15000]))\n",
        "print(sum(rewards_all[19000:]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12575.0\n",
            "161.0\n",
            "426.0\n",
            "489.0\n",
            "687.0\n",
            "680.0\n",
            "698.0\n",
            "704.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGopsD0IWpDO"
      },
      "source": [
        "def play(env, q_table, render=False):\n",
        "    state = env.reset()\n",
        "    total_reward = 0\n",
        "    steps = 0\n",
        "    done = False\n",
        "    while not done:\n",
        "        action = np.argmax(q_table[state, :])\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "        total_reward += reward\n",
        "        steps += 1\n",
        "        if render:\n",
        "            env.render()\n",
        "            time.sleep(0.2)\n",
        "            if not done:\n",
        "                display.clear_output(wait=True)\n",
        "        state = next_state\n",
        "\n",
        "    return (total_reward, steps)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def play_multiple_times(env, q_table, max_episodes):\n",
        "    success = 0\n",
        "    list_of_steps = []\n",
        "    for i in range(max_episodes):\n",
        "        total_reward, steps = play(env, q_table)\n",
        "\n",
        "        if total_reward > 0:\n",
        "            success += 1\n",
        "            list_of_steps.append(steps)\n",
        "\n",
        "    print(f'Number of successes: {success}/{max_episodes}')\n",
        "    print(f'Average number of steps: {np.mean(list_of_steps)}')"
      ],
      "metadata": {
        "id": "2l8BKi9TSqRe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "play_multiple_times(env, q_table, 1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hs-EbCUUSvf2",
        "outputId": "939d5ed8-7e68-4712-d062-f83f9588e4cd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of successes: 708/1000\n",
            "Average number of steps: 36.693502824858754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bm4CcsAzSx-f"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SARSA"
      ],
      "metadata": {
        "id": "65LMZDjV3OXu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2afe844-7012-4077-c85e-cd336e17194a",
        "id": "6B_3FBNS3OXv"
      },
      "source": [
        "# Initialize Q-value table randomly\n",
        "q_table = np.zeros((env.observation_space.n, env.action_space.n))\n",
        "print(q_table)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndrAGPFw3OXv"
      },
      "source": [
        "# Hyperparameters\n",
        "gamma = 0.99\n",
        "learning_rate = 0.1\n",
        "max_epsilon = 1.0\n",
        "min_epsilon = 0.01\n",
        "epsilon_decay_rate = 0.005\n",
        "\n",
        "num_episodes = 20000\n",
        "num_steps_per_episode = 100"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09w_1RR13OXw"
      },
      "source": [
        "def sarsa(env, num_episodes, num_steps_per_episode, learning_rate, gamma, max_epsilon, min_epsilon, epsilon_decay_rate):\n",
        "    q_table = np.zeros((env.observation_space.n, env.action_space.n))\n",
        "    rewards_all = []\n",
        "    for episode in range(num_episodes):\n",
        "        state = env.reset()\n",
        "\n",
        "        reward_episode = 0.0\n",
        "        done = False\n",
        "        epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-epsilon_decay_rate*episode)\n",
        "\n",
        "        exploration = random.uniform(0,1)\n",
        "        if exploration < epsilon:\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            action = np.argmax(q_table[state, :])\n",
        "\n",
        "        for step in range(num_steps_per_episode):\n",
        "\n",
        "            next_state, reward, done, info = env.step(action)\n",
        "\n",
        "            exploration = random.uniform(0,1)\n",
        "            if exploration < epsilon:\n",
        "                next_action = env.action_space.sample()\n",
        "            else:\n",
        "                next_action = np.argmax(q_table[next_state, :])\n",
        "\n",
        "\n",
        "            q_table[state, action] = q_table[state, action] * (1 - learning_rate) + learning_rate * (reward + gamma * q_table[next_state, next_action])\n",
        "\n",
        "            reward_episode += reward\n",
        "            state = next_state\n",
        "            action = next_action\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "        rewards_all.append(reward_episode)\n",
        "    print(f'Episode {episode} finished')\n",
        "    return q_table, rewards_all"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TEST"
      ],
      "metadata": {
        "id": "hyCsTqi53OXw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "230498d9-cfb7-4584-c1f8-23f8c4da7a86",
        "id": "H1BQ0ymU3OXw"
      },
      "source": [
        "q_table, rewards_all = sarsa(env, num_episodes, num_steps_per_episode, learning_rate, gamma, max_epsilon, min_epsilon, epsilon_decay_rate)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 19999 finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f33d7cc5-88a5-43ff-f78b-8eda124a68c0",
        "id": "Ihh_0tmx3OXw"
      },
      "source": [
        "q_table"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.53753331, 0.47856003, 0.49161675, 0.4758208 ],\n",
              "       [0.31531931, 0.39583936, 0.22441657, 0.48169993],\n",
              "       [0.38460171, 0.3806945 , 0.35239827, 0.44552165],\n",
              "       [0.27545707, 0.22215938, 0.23299918, 0.42419435],\n",
              "       [0.54959234, 0.32951249, 0.35363378, 0.3160213 ],\n",
              "       [0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.35004829, 0.14647783, 0.18716203, 0.16056844],\n",
              "       [0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.31804055, 0.41171648, 0.28963147, 0.59465981],\n",
              "       [0.42457454, 0.62121669, 0.38198078, 0.45631307],\n",
              "       [0.61653384, 0.42645396, 0.19783077, 0.28958207],\n",
              "       [0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.44801434, 0.39994589, 0.71284392, 0.56214048],\n",
              "       [0.71701333, 0.90090435, 0.74842935, 0.76764452],\n",
              "       [0.        , 0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2188e646-104a-44dc-dfb4-f998eff772ec",
        "id": "tb1vQ57t3OXx"
      },
      "source": [
        "print(sum(rewards_all))\n",
        "print(sum(rewards_all[0:1000]))\n",
        "print(sum(rewards_all[1000:2000]))\n",
        "print(sum(rewards_all[2000:3000]))\n",
        "print(sum(rewards_all[9000:10000]))\n",
        "print(sum(rewards_all[11000:12000]))\n",
        "print(sum(rewards_all[14000:15000]))\n",
        "print(sum(rewards_all[19000:]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12981.0\n",
            "239.0\n",
            "597.0\n",
            "648.0\n",
            "658.0\n",
            "676.0\n",
            "698.0\n",
            "693.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SokFrgEz3OXx"
      },
      "source": [
        "def play(env, q_table, render=False):\n",
        "    state = env.reset()\n",
        "    total_reward = 0\n",
        "    steps = 0\n",
        "    done = False\n",
        "    while not done:\n",
        "        action = np.argmax(q_table[state, :])\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "        total_reward += reward\n",
        "        steps += 1\n",
        "        if render:\n",
        "            env.render()\n",
        "            time.sleep(0.2)\n",
        "            if not done:\n",
        "                display.clear_output(wait=True)\n",
        "        state = next_state\n",
        "\n",
        "    return (total_reward, steps)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def play_multiple_times(env, q_table, max_episodes):\n",
        "    success = 0\n",
        "    list_of_steps = []\n",
        "    for i in range(max_episodes):\n",
        "        total_reward, steps = play(env, q_table)\n",
        "\n",
        "        if total_reward > 0:\n",
        "            success += 1\n",
        "            list_of_steps.append(steps)\n",
        "\n",
        "    print(f'Number of successes: {success}/{max_episodes}')\n",
        "    print(f'Average number of steps: {np.mean(list_of_steps)}')"
      ],
      "metadata": {
        "id": "Q3jrcqrj3OXx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "play_multiple_times(env, q_table, 1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23ca1de6-fc25-47e4-d466-09679b8d3250",
        "id": "2-QJubEY3OXx"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of successes: 750/1000\n",
            "Average number of steps: 37.48133333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4_d-Lc9J3OXx"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}